<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "urn:pubid:dita4publishers.sourceforge.net:doctypes:dita:topic" "topic.dtd">
<topic id="d1e55"><title>Exercise 3.11</title><body><p>
<b>Prove: any
<d4p_eqn_inline>
    <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mrow><m:mi>k</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:math></d4p_MathML>
  </d4p_eqn_inline> k-vectors are linearly dependent. (You can do it by using  mathematical induction.)</b>
</p><p>
Solution:
</p><p>
Suppose we have 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mrow><m:mi>k</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:math></d4p_MathML>
</d4p_eqn_inline>
 k-vectors. Each such vector has 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mi>k</m:mi></m:math></d4p_MathML>
</d4p_eqn_inline>
 components. We assume as an induction hypothesis that any 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mi>k</m:mi></m:math></d4p_MathML>
</d4p_eqn_inline>
 (k-1)-vectors are linearly dependent, which means that there must be a linear dependence among any 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mi>k</m:mi></m:math></d4p_MathML>
</d4p_eqn_inline>
 (k-1)-component vectors.
</p><p>
(This hypothesis is trivial for 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mrow><m:mi>k</m:mi><m:mo>=</m:mo><m:mn>2</m:mn></m:mrow></m:math></d4p_MathML>
</d4p_eqn_inline>
 )
</p><p>
We notice that a linear combination of linear combinations is a linear combination. This means if we can take our 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mrow><m:mi>k</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:math></d4p_MathML>
</d4p_eqn_inline>
 k-vectors and produce 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mi>k</m:mi></m:math></d4p_MathML>
</d4p_eqn_inline>
 linear distinct linear combinations of them that are each (k-1)-vectors, we can use the induction hypothesis to give us a linear dependence among these which will produce a linear dependence among our original vectors.
</p><p>
Notice also that k-vectors all of whose last components are 0 can be considered to be k-1-vectors.
</p><p>
So we pick one of our vectors, say the k-th, which has a non-zero k-th component. (if there is no vector with non-zero k-th component, then we really have k-1-component vectors and can apply the induction hypothesis immediately) Now we subtract enough of this vector from each of the others to make the resulting k-th components all zero.
</p><p>
Now we have our 
<d4p_eqn_inline>
  <d4p_MathML><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline" overflow="scroll"><m:mi>k</m:mi></m:math></d4p_MathML>
</d4p_eqn_inline>
 (k-1)-vectors and find a linear combination that is 0. This gives a linear combination of the original vectors which is 0 and we are done.
</p><p>
We have to verify that the new linear combination cannot have all 0 coefficients if the one obtained from the induction hypothesis did not. This is obvious because each of our vectors except for the k-th occurs in exactly one of the combinations to which the induction hypothesis was applied. Any non-zero coefficient in the linear combination of linear combinations will give rise to a non-zero coefficient of the corresponding one of our original vectors and we are really done.
<br/>
</p></body></topic>